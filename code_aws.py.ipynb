{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import sagemaker.amazon.common as smac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!conda install -y s3fs\n",
    "\n",
    "import boto3\n",
    "import s3fs\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "##The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "#The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Here we use the get_execution_role function to obtain the role arn which was specified when creating the notebook.\n",
    "bucket = 'data'\n",
    "prefix = 'rnd'\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "s3_data_path = \"{}/{}/2013-8/\".format(bucket, prefix)\n",
    "s3_output_path = \"{}/{}/output\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(os.path.join(s3_data_path, \"1*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f, sep = ';\\t') for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df['Timestamp'] = pd.to_datetime(concatenated_df['Timestamp [ms]'], unit = 's')\n",
    "concatenated_df.apply(pd.to_numeric, errors='ignore')\n",
    "concatenated_df.describe()\n",
    "concatenated_df['weekday'] = concatenated_df['Timestamp'].dt.dayofweek\n",
    "\n",
    "\n",
    "concatenated_df['weekend'] = ((concatenated_df.weekday) // 5 == 1).astype(float)\n",
    "# Feature engineering with the date\n",
    "concatenated_df['month']=concatenated_df.Timestamp.dt.month \n",
    "concatenated_df['day']=concatenated_df.Timestamp.dt.day\n",
    "concatenated_df.set_index('Timestamp',inplace=True)\n",
    "concatenated_df[\"CPU usage prev\"] = concatenated_df['CPU usage [%]'].shift(1)\n",
    "concatenated_df[\"CPU_diff\"] = concatenated_df['CPU usage [%]'] - concatenated_df[\"CPU usage prev\"]\n",
    "concatenated_df[\"received_prev\"] = concatenated_df['Network received throughput [KB/s]'].shift(1)\n",
    "concatenated_df[\"received_diff\"] = concatenated_df['Network received throughput [KB/s]']- concatenated_df[\"received_prev\"]\n",
    "\n",
    "concatenated_df[\"transmitted_prev\"] = concatenated_df['Network transmitted throughput [KB/s]'].shift(1)\n",
    "concatenated_df[\"transmitted_diff\"] = concatenated_df['Network transmitted throughput [KB/s]']- concatenated_df[\"transmitted_prev\"]\n",
    "\n",
    "cpu = concatenated_df[['CPU usage [MHZ]']]\n",
    "receive = concatenated_df[['Network received throughput [KB/s]']]\n",
    "transmit = concatenated_df[['Network transmitted throughput [KB/s]']]\n",
    "#concatenated_df.drop('CPU capacity provisioned [MHZ]', axis=1, inplace=True)\n",
    "#concatenated_df.drop('Memory capacity provisioned [KB]', axis=1, inplace=True)\n",
    "concatenated_df.drop('Timestamp [ms]', axis=1, inplace=True) \n",
    "#concatenated_df.drop('Memory usage [KB]', axis=1, inplace=True)\n",
    "provisioned = concatenated_df[['CPU capacity provisioned [MHZ]']]\n",
    "\n",
    "moving_average(cpu, 24) # prediction for the last observed day (past 24 hours)\n",
    "hourlydat = concatenated_df.resample('H').sum()\n",
    "#hourlydat.iloc[:,5:7].plot(style=[':', '--', '-'], figsize=(20,10), linewidth=3, fontsize=20)\n",
    "#plt.ylabel('Resampled Data');\n",
    "hourlycpu = cpu.resample('H').sum()\n",
    "hourlytransmit = transmit.resample('H').sum()\n",
    "hourlyreceive = receive.resample('H').sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlydat[\"start\"] = hourlydat.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlydat['target'] = hourlydat['CPU usage [MHZ]']\n",
    "\n",
    "jsondat=pd.DataFrame(hourlydat['start'])\n",
    "\n",
    "jsondat['start'] = hourlydat.index\n",
    "\n",
    "result = pd.concat([hourlydat['start'], hourlydat['target']], axis=1, sort=False)\n",
    "\n",
    "result = result.reset_index()\n",
    "\n",
    "result.drop('Timestamp', axis=1, inplace=True)\n",
    "\n",
    "result.start = result.start.astype(str)\n",
    "\n",
    "#result.set_index('start',inplace=True)\n",
    "\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
